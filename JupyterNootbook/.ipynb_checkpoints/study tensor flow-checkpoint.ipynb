{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'session'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ec27e3734c08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'session'"
     ]
    }
   ],
   "source": [
    "tf.session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建常量op\n",
    "m1 = tf.constant([[3,3]])\n",
    "m2 = tf.constant([[2],[3]])\n",
    "product = tf.matmul(m1,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul:0' shape=(1, 1) dtype=int32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "result = sess.run(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    result = sess.run(product)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2 -1]\n",
      "[4 5]\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([1,2])\n",
    "a = tf.constant([3,3])\n",
    "sub = tf.subtract(x,a)\n",
    "add = tf.add(x,a)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(sub))\n",
    "    print(sess.run(add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Tensor(\"Assign_8:0\", shape=(), dtype=int32_ref)\n",
      "1\n",
      "Tensor(\"Add_12:0\", shape=(), dtype=int32)\n",
      "2\n",
      "Tensor(\"Assign_8:0\", shape=(), dtype=int32_ref)\n",
      "2\n",
      "Tensor(\"Add_12:0\", shape=(), dtype=int32)\n",
      "3\n",
      "Tensor(\"Assign_8:0\", shape=(), dtype=int32_ref)\n",
      "3\n",
      "Tensor(\"Add_12:0\", shape=(), dtype=int32)\n",
      "4\n",
      "Tensor(\"Assign_8:0\", shape=(), dtype=int32_ref)\n",
      "4\n",
      "Tensor(\"Add_12:0\", shape=(), dtype=int32)\n",
      "5\n",
      "Tensor(\"Assign_8:0\", shape=(), dtype=int32_ref)\n",
      "5\n",
      "Tensor(\"Add_12:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "state = tf.Variable(0,name='counter')\n",
    "\n",
    "new_value = tf.add(state,1)\n",
    "update = tf.assign(state, new_value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(state))\n",
    "    for _ in range(5):\n",
    "        print(sess.run(update))\n",
    "        print(update)\n",
    "        print(sess.run(state))\n",
    "        print(new_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16.0, 8.0]\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.constant(2.0)\n",
    "input2 = tf.constant(3.0)\n",
    "input3 = tf.constant(5.0)\n",
    "\n",
    "add = tf.add(input2, input3)\n",
    "mul = tf.multiply(input1, add)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run([mul, add])\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.]\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "output = tf.multiply(input1, input2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(output, feed_dict={input1:[7.0], input2:[2.0]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.04874996, 0.09851584, 0.015883613]\n",
      "20 [0.09949306, 0.20025055, 2.047364e-08]\n",
      "40 [0.09969831, 0.20014921, 7.252731e-09]\n",
      "60 [0.09982044, 0.2000888, 2.5691502e-09]\n",
      "80 [0.099893145, 0.20005284, 9.0983165e-10]\n",
      "100 [0.0999364, 0.20003144, 3.222314e-10]\n",
      "120 [0.09996216, 0.2000187, 1.1408816e-10]\n",
      "140 [0.09997748, 0.20001113, 4.0418446e-11]\n",
      "160 [0.0999866, 0.20000662, 1.4307036e-11]\n",
      "180 [0.09999203, 0.20000395, 5.0680905e-12]\n",
      "200 [0.099995255, 0.20000236, 1.7983992e-12]\n"
     ]
    }
   ],
   "source": [
    "x_data = np.random.rand(100)\n",
    "y_data = x_data*0.1 + 0.2\n",
    "\n",
    "b = tf.Variable(0.)\n",
    "k = tf.Variable(0.)\n",
    "y = k*x_data + b\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y_data-y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.2)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(201):\n",
    "        sess.run(train)\n",
    "        if step%20 == 0:\n",
    "            print(step, sess.run([k,b,loss]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_data = np.linspace(-0.5, 0.5, 200)[:,np.newaxis]\n",
    "noise = np.random.normal(0, 0.02, x_data.shape)\n",
    "y_data = np.square(x_data) + noise\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None,1])\n",
    "y = tf.placeholder(tf.float32, [None,1])\n",
    "\n",
    "Weight_L1 = tf.Variable(tf.random_normal([1,10]))\n",
    "biases_L1 = tf.Variable(tf.zeros([1,10]))\n",
    "Wx_plus_b_L1 = tf.matmul(x, Weight_L1) + biases_L1\n",
    "L1 = tf.nn.tanh(Wx_plus_b_L1)\n",
    "\n",
    "Weight_L2 = tf.Variable(tf.random_normal([10,1]))\n",
    "biases_L2 = tf.Variable(tf.zeros([1,1]))\n",
    "Wx_plus_b_L2 = tf.matmul(L1, Weight_L2) + biases_L2\n",
    "prediction = tf.nn.tanh(Wx_plus_b_L2)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for _ in range(2000):\n",
    "        sess.run(train_step, feed_dict={x:x_data, y:y_data})\n",
    "    \n",
    "    prediction_value = sess.run(prediction, feed_dict={x:x_data})\n",
    "    plt.figure()\n",
    "    plt.scatter(x_data, y_data)\n",
    "    plt.plot(x_data, prediction_value, 'r-', lw=5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MINIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MINIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MINIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MINIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MINIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 , testing accuracy 0.1211\n",
      "Iter 1 , testing accuracy 0.1328\n",
      "Iter 2 , testing accuracy 0.1447\n",
      "Iter 3 , testing accuracy 0.1543\n",
      "Iter 4 , testing accuracy 0.1637\n",
      "Iter 5 , testing accuracy 0.1714\n",
      "Iter 6 , testing accuracy 0.1809\n",
      "Iter 7 , testing accuracy 0.1886\n",
      "Iter 8 , testing accuracy 0.1951\n",
      "Iter 9 , testing accuracy 0.2035\n",
      "Iter 10 , testing accuracy 0.2091\n",
      "Iter 11 , testing accuracy 0.2164\n",
      "Iter 12 , testing accuracy 0.2267\n",
      "Iter 13 , testing accuracy 0.2436\n",
      "Iter 14 , testing accuracy 0.2646\n",
      "Iter 15 , testing accuracy 0.2936\n",
      "Iter 16 , testing accuracy 0.3276\n",
      "Iter 17 , testing accuracy 0.3799\n",
      "Iter 18 , testing accuracy 0.4389\n",
      "Iter 19 , testing accuracy 0.4869\n",
      "Iter 20 , testing accuracy 0.5208\n",
      "Iter 21 , testing accuracy 0.5505\n",
      "Iter 22 , testing accuracy 0.5734\n",
      "Iter 23 , testing accuracy 0.5923\n",
      "Iter 24 , testing accuracy 0.6069\n",
      "Iter 25 , testing accuracy 0.6212\n",
      "Iter 26 , testing accuracy 0.6349\n",
      "Iter 27 , testing accuracy 0.6439\n",
      "Iter 28 , testing accuracy 0.6537\n",
      "Iter 29 , testing accuracy 0.6629\n",
      "Iter 30 , testing accuracy 0.67\n",
      "Iter 31 , testing accuracy 0.6771\n",
      "Iter 32 , testing accuracy 0.6818\n",
      "Iter 33 , testing accuracy 0.686\n",
      "Iter 34 , testing accuracy 0.6902\n",
      "Iter 35 , testing accuracy 0.694\n",
      "Iter 36 , testing accuracy 0.6992\n",
      "Iter 37 , testing accuracy 0.7018\n",
      "Iter 38 , testing accuracy 0.7065\n",
      "Iter 39 , testing accuracy 0.7101\n",
      "Iter 40 , testing accuracy 0.7128\n",
      "Iter 41 , testing accuracy 0.7163\n",
      "Iter 42 , testing accuracy 0.719\n",
      "Iter 43 , testing accuracy 0.7209\n",
      "Iter 44 , testing accuracy 0.7243\n",
      "Iter 45 , testing accuracy 0.7257\n",
      "Iter 46 , testing accuracy 0.7284\n",
      "Iter 47 , testing accuracy 0.7311\n",
      "Iter 48 , testing accuracy 0.7325\n",
      "Iter 49 , testing accuracy 0.7341\n",
      "Iter 50 , testing accuracy 0.7355\n",
      "Iter 51 , testing accuracy 0.7378\n",
      "Iter 52 , testing accuracy 0.7393\n",
      "Iter 53 , testing accuracy 0.7405\n",
      "Iter 54 , testing accuracy 0.7412\n",
      "Iter 55 , testing accuracy 0.7414\n",
      "Iter 56 , testing accuracy 0.7431\n",
      "Iter 57 , testing accuracy 0.7446\n",
      "Iter 58 , testing accuracy 0.7448\n",
      "Iter 59 , testing accuracy 0.7465\n",
      "Iter 60 , testing accuracy 0.747\n",
      "Iter 61 , testing accuracy 0.7488\n",
      "Iter 62 , testing accuracy 0.75\n",
      "Iter 63 , testing accuracy 0.7504\n",
      "Iter 64 , testing accuracy 0.7515\n",
      "Iter 65 , testing accuracy 0.7525\n",
      "Iter 66 , testing accuracy 0.7534\n",
      "Iter 67 , testing accuracy 0.7544\n",
      "Iter 68 , testing accuracy 0.7541\n",
      "Iter 69 , testing accuracy 0.7552\n",
      "Iter 70 , testing accuracy 0.7556\n",
      "Iter 71 , testing accuracy 0.7566\n",
      "Iter 72 , testing accuracy 0.7569\n",
      "Iter 73 , testing accuracy 0.7573\n",
      "Iter 74 , testing accuracy 0.7578\n",
      "Iter 75 , testing accuracy 0.758\n",
      "Iter 76 , testing accuracy 0.7581\n",
      "Iter 77 , testing accuracy 0.7596\n",
      "Iter 78 , testing accuracy 0.7601\n",
      "Iter 79 , testing accuracy 0.7612\n",
      "Iter 80 , testing accuracy 0.7618\n",
      "Iter 81 , testing accuracy 0.7623\n",
      "Iter 82 , testing accuracy 0.7629\n",
      "Iter 83 , testing accuracy 0.7626\n",
      "Iter 84 , testing accuracy 0.7638\n",
      "Iter 85 , testing accuracy 0.7639\n",
      "Iter 86 , testing accuracy 0.7648\n",
      "Iter 87 , testing accuracy 0.7653\n",
      "Iter 88 , testing accuracy 0.7661\n",
      "Iter 89 , testing accuracy 0.7667\n",
      "Iter 90 , testing accuracy 0.7681\n",
      "Iter 91 , testing accuracy 0.7685\n",
      "Iter 92 , testing accuracy 0.7686\n",
      "Iter 93 , testing accuracy 0.7696\n",
      "Iter 94 , testing accuracy 0.7697\n",
      "Iter 95 , testing accuracy 0.7696\n",
      "Iter 96 , testing accuracy 0.771\n",
      "Iter 97 , testing accuracy 0.7713\n",
      "Iter 98 , testing accuracy 0.7718\n",
      "Iter 99 , testing accuracy 0.772\n",
      "Iter 100 , testing accuracy 0.7724\n",
      "Iter 101 , testing accuracy 0.7727\n",
      "Iter 102 , testing accuracy 0.7735\n",
      "Iter 103 , testing accuracy 0.7729\n",
      "Iter 104 , testing accuracy 0.7732\n",
      "Iter 105 , testing accuracy 0.7738\n",
      "Iter 106 , testing accuracy 0.7744\n",
      "Iter 107 , testing accuracy 0.7746\n",
      "Iter 108 , testing accuracy 0.7751\n",
      "Iter 109 , testing accuracy 0.7755\n",
      "Iter 110 , testing accuracy 0.7762\n",
      "Iter 111 , testing accuracy 0.7759\n",
      "Iter 112 , testing accuracy 0.7772\n",
      "Iter 113 , testing accuracy 0.7774\n",
      "Iter 114 , testing accuracy 0.777\n",
      "Iter 115 , testing accuracy 0.7777\n",
      "Iter 116 , testing accuracy 0.7788\n",
      "Iter 117 , testing accuracy 0.7793\n",
      "Iter 118 , testing accuracy 0.7789\n",
      "Iter 119 , testing accuracy 0.7808\n",
      "Iter 120 , testing accuracy 0.7813\n",
      "Iter 121 , testing accuracy 0.7816\n",
      "Iter 122 , testing accuracy 0.7824\n",
      "Iter 123 , testing accuracy 0.7827\n",
      "Iter 124 , testing accuracy 0.7827\n",
      "Iter 125 , testing accuracy 0.7828\n",
      "Iter 126 , testing accuracy 0.7843\n",
      "Iter 127 , testing accuracy 0.7854\n",
      "Iter 128 , testing accuracy 0.7844\n",
      "Iter 129 , testing accuracy 0.7855\n",
      "Iter 130 , testing accuracy 0.7862\n",
      "Iter 131 , testing accuracy 0.7869\n",
      "Iter 132 , testing accuracy 0.7872\n",
      "Iter 133 , testing accuracy 0.7876\n",
      "Iter 134 , testing accuracy 0.7886\n",
      "Iter 135 , testing accuracy 0.7892\n",
      "Iter 136 , testing accuracy 0.7902\n",
      "Iter 137 , testing accuracy 0.7913\n",
      "Iter 138 , testing accuracy 0.7916\n",
      "Iter 139 , testing accuracy 0.7923\n",
      "Iter 140 , testing accuracy 0.7931\n",
      "Iter 141 , testing accuracy 0.7946\n",
      "Iter 142 , testing accuracy 0.7957\n",
      "Iter 143 , testing accuracy 0.797\n",
      "Iter 144 , testing accuracy 0.7985\n",
      "Iter 145 , testing accuracy 0.8002\n",
      "Iter 146 , testing accuracy 0.8009\n",
      "Iter 147 , testing accuracy 0.8023\n",
      "Iter 148 , testing accuracy 0.8051\n",
      "Iter 149 , testing accuracy 0.8066\n",
      "Iter 150 , testing accuracy 0.8099\n",
      "Iter 151 , testing accuracy 0.8121\n",
      "Iter 152 , testing accuracy 0.8132\n",
      "Iter 153 , testing accuracy 0.8146\n",
      "Iter 154 , testing accuracy 0.816\n",
      "Iter 155 , testing accuracy 0.8181\n",
      "Iter 156 , testing accuracy 0.8201\n",
      "Iter 157 , testing accuracy 0.821\n",
      "Iter 158 , testing accuracy 0.823\n",
      "Iter 159 , testing accuracy 0.8254\n",
      "Iter 160 , testing accuracy 0.8267\n",
      "Iter 161 , testing accuracy 0.8282\n",
      "Iter 162 , testing accuracy 0.8304\n",
      "Iter 163 , testing accuracy 0.8315\n",
      "Iter 164 , testing accuracy 0.834\n",
      "Iter 165 , testing accuracy 0.8347\n",
      "Iter 166 , testing accuracy 0.8369\n",
      "Iter 167 , testing accuracy 0.8384\n",
      "Iter 168 , testing accuracy 0.8406\n",
      "Iter 169 , testing accuracy 0.842\n",
      "Iter 170 , testing accuracy 0.8435\n",
      "Iter 171 , testing accuracy 0.8444\n",
      "Iter 172 , testing accuracy 0.8468\n",
      "Iter 173 , testing accuracy 0.8487\n",
      "Iter 174 , testing accuracy 0.8496\n",
      "Iter 175 , testing accuracy 0.8497\n",
      "Iter 176 , testing accuracy 0.8513\n",
      "Iter 177 , testing accuracy 0.8515\n",
      "Iter 178 , testing accuracy 0.8525\n",
      "Iter 179 , testing accuracy 0.8527\n",
      "Iter 180 , testing accuracy 0.8537\n",
      "Iter 181 , testing accuracy 0.8543\n",
      "Iter 182 , testing accuracy 0.8551\n",
      "Iter 183 , testing accuracy 0.8565\n",
      "Iter 184 , testing accuracy 0.8572\n",
      "Iter 185 , testing accuracy 0.8587\n",
      "Iter 186 , testing accuracy 0.8589\n",
      "Iter 187 , testing accuracy 0.8597\n",
      "Iter 188 , testing accuracy 0.8601\n",
      "Iter 189 , testing accuracy 0.8608\n",
      "Iter 190 , testing accuracy 0.8618\n",
      "Iter 191 , testing accuracy 0.8625\n",
      "Iter 192 , testing accuracy 0.863\n",
      "Iter 193 , testing accuracy 0.8629\n",
      "Iter 194 , testing accuracy 0.8627\n",
      "Iter 195 , testing accuracy 0.8637\n",
      "Iter 196 , testing accuracy 0.8636\n",
      "Iter 197 , testing accuracy 0.8639\n",
      "Iter 198 , testing accuracy 0.8649\n",
      "Iter 199 , testing accuracy 0.8651\n",
      "Iter 200 , testing accuracy 0.866\n",
      "Iter 201 , testing accuracy 0.8657\n",
      "Iter 202 , testing accuracy 0.8662\n",
      "Iter 203 , testing accuracy 0.8673\n",
      "Iter 204 , testing accuracy 0.8676\n",
      "Iter 205 , testing accuracy 0.8675\n",
      "Iter 206 , testing accuracy 0.868\n",
      "Iter 207 , testing accuracy 0.8685\n",
      "Iter 208 , testing accuracy 0.8689\n",
      "Iter 209 , testing accuracy 0.869\n",
      "Iter 210 , testing accuracy 0.8699\n",
      "Iter 211 , testing accuracy 0.8702\n",
      "Iter 212 , testing accuracy 0.8699\n",
      "Iter 213 , testing accuracy 0.8701\n",
      "Iter 214 , testing accuracy 0.8705\n",
      "Iter 215 , testing accuracy 0.8704\n",
      "Iter 216 , testing accuracy 0.8707\n",
      "Iter 217 , testing accuracy 0.8716\n",
      "Iter 218 , testing accuracy 0.8722\n",
      "Iter 219 , testing accuracy 0.8716\n",
      "Iter 220 , testing accuracy 0.8714\n",
      "Iter 221 , testing accuracy 0.8719\n",
      "Iter 222 , testing accuracy 0.8724\n",
      "Iter 223 , testing accuracy 0.8729\n",
      "Iter 224 , testing accuracy 0.8732\n",
      "Iter 225 , testing accuracy 0.8722\n",
      "Iter 226 , testing accuracy 0.8723\n",
      "Iter 227 , testing accuracy 0.8728\n",
      "Iter 228 , testing accuracy 0.8735\n",
      "Iter 229 , testing accuracy 0.8735\n",
      "Iter 230 , testing accuracy 0.8733\n",
      "Iter 231 , testing accuracy 0.8737\n",
      "Iter 232 , testing accuracy 0.8738\n",
      "Iter 233 , testing accuracy 0.8744\n",
      "Iter 234 , testing accuracy 0.8739\n",
      "Iter 235 , testing accuracy 0.8742\n",
      "Iter 236 , testing accuracy 0.8737\n",
      "Iter 237 , testing accuracy 0.8746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 238 , testing accuracy 0.8746\n",
      "Iter 239 , testing accuracy 0.8742\n",
      "Iter 240 , testing accuracy 0.8745\n",
      "Iter 241 , testing accuracy 0.875\n",
      "Iter 242 , testing accuracy 0.8745\n",
      "Iter 243 , testing accuracy 0.875\n",
      "Iter 244 , testing accuracy 0.8759\n",
      "Iter 245 , testing accuracy 0.8753\n",
      "Iter 246 , testing accuracy 0.8761\n",
      "Iter 247 , testing accuracy 0.8753\n",
      "Iter 248 , testing accuracy 0.8755\n",
      "Iter 249 , testing accuracy 0.8759\n",
      "Iter 250 , testing accuracy 0.8762\n",
      "Iter 251 , testing accuracy 0.8762\n",
      "Iter 252 , testing accuracy 0.8762\n",
      "Iter 253 , testing accuracy 0.8764\n",
      "Iter 254 , testing accuracy 0.8765\n",
      "Iter 255 , testing accuracy 0.8769\n",
      "Iter 256 , testing accuracy 0.8771\n",
      "Iter 257 , testing accuracy 0.8775\n",
      "Iter 258 , testing accuracy 0.8772\n",
      "Iter 259 , testing accuracy 0.8769\n",
      "Iter 260 , testing accuracy 0.8772\n",
      "Iter 261 , testing accuracy 0.8773\n",
      "Iter 262 , testing accuracy 0.8774\n",
      "Iter 263 , testing accuracy 0.8767\n",
      "Iter 264 , testing accuracy 0.878\n",
      "Iter 265 , testing accuracy 0.8774\n",
      "Iter 266 , testing accuracy 0.8778\n",
      "Iter 267 , testing accuracy 0.8773\n",
      "Iter 268 , testing accuracy 0.8773\n",
      "Iter 269 , testing accuracy 0.877\n",
      "Iter 270 , testing accuracy 0.8774\n",
      "Iter 271 , testing accuracy 0.877\n",
      "Iter 272 , testing accuracy 0.8774\n",
      "Iter 273 , testing accuracy 0.8776\n",
      "Iter 274 , testing accuracy 0.8776\n",
      "Iter 275 , testing accuracy 0.8767\n",
      "Iter 276 , testing accuracy 0.8776\n",
      "Iter 277 , testing accuracy 0.8774\n",
      "Iter 278 , testing accuracy 0.8786\n",
      "Iter 279 , testing accuracy 0.8784\n",
      "Iter 280 , testing accuracy 0.8781\n",
      "Iter 281 , testing accuracy 0.8785\n",
      "Iter 282 , testing accuracy 0.8782\n",
      "Iter 283 , testing accuracy 0.8786\n",
      "Iter 284 , testing accuracy 0.8787\n",
      "Iter 285 , testing accuracy 0.8791\n",
      "Iter 286 , testing accuracy 0.8788\n",
      "Iter 287 , testing accuracy 0.8785\n",
      "Iter 288 , testing accuracy 0.879\n",
      "Iter 289 , testing accuracy 0.8792\n",
      "Iter 290 , testing accuracy 0.8795\n",
      "Iter 291 , testing accuracy 0.8793\n",
      "Iter 292 , testing accuracy 0.8793\n",
      "Iter 293 , testing accuracy 0.8793\n",
      "Iter 294 , testing accuracy 0.8798\n",
      "Iter 295 , testing accuracy 0.8803\n",
      "Iter 296 , testing accuracy 0.8795\n",
      "Iter 297 , testing accuracy 0.8798\n",
      "Iter 298 , testing accuracy 0.8799\n",
      "Iter 299 , testing accuracy 0.8806\n"
     ]
    }
   ],
   "source": [
    "# 每个批次的大小 每次放入100张图片\n",
    "batch_size = 40\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size  # 整除\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#创建神经网路\n",
    "\n",
    "Weight_L1 = tf.Variable(tf.random_normal([784,200]))\n",
    "biases_L1 = tf.Variable(tf.random_normal([1,200]))\n",
    "Wx_plus_b_L1 = tf.matmul(x, Weight_L1) + biases_L1\n",
    "L1 = tf.nn.tanh(Wx_plus_b_L1)\n",
    "#L1 = tf.nn.softmax(Wx_plus_b_L1)\n",
    "#L1 = Wx_plus_b_L1\n",
    "\n",
    "#Weight_L2 = tf.Variable(tf.random_normal([200,10]))\n",
    "Weight_L2 = tf.Variable(tf.random_normal([200,10]))\n",
    "biases_L2 = tf.Variable(tf.random_normal([1,10]))\n",
    "Wx_plus_b_L2 = tf.matmul(L1, Weight_L2) + biases_L2\n",
    "\n",
    "#b = tf.Variable(tf.zeros([1,10]))\n",
    "L2 = tf.nn.tanh(Wx_plus_b_L2)\n",
    "\n",
    "\n",
    "prediction = tf.nn.softmax(L2)\n",
    "\n",
    "\n",
    "# 二次代价函数\n",
    "loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(prediction,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(300):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x:batch_xs, y:batch_ys})\n",
    "            \n",
    "        acc = sess.run(accuracy, feed_dict={x:mnist.test.images, y:mnist.test.labels})\n",
    "        print(\"Iter \" +str(epoch) + \" , testing accuracy \" + str(acc))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 , testing accuracy 0.8759\n",
      "Iter 1 , testing accuracy 0.8926\n",
      "Iter 2 , testing accuracy 0.9004\n",
      "Iter 3 , testing accuracy 0.9059\n",
      "Iter 4 , testing accuracy 0.9072\n",
      "Iter 5 , testing accuracy 0.9101\n",
      "Iter 6 , testing accuracy 0.913\n",
      "Iter 7 , testing accuracy 0.9138\n",
      "Iter 8 , testing accuracy 0.9156\n",
      "Iter 9 , testing accuracy 0.9159\n",
      "Iter 10 , testing accuracy 0.9171\n",
      "Iter 11 , testing accuracy 0.9185\n",
      "Iter 12 , testing accuracy 0.9185\n",
      "Iter 13 , testing accuracy 0.919\n",
      "Iter 14 , testing accuracy 0.9197\n",
      "Iter 15 , testing accuracy 0.9191\n",
      "Iter 16 , testing accuracy 0.9202\n",
      "Iter 17 , testing accuracy 0.9206\n",
      "Iter 18 , testing accuracy 0.9217\n",
      "Iter 19 , testing accuracy 0.9213\n",
      "Iter 20 , testing accuracy 0.9217\n"
     ]
    }
   ],
   "source": [
    "# 每个批次的大小 每次放入100张图片\n",
    "batch_size = 40\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size  # 整除\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#创建神经网路\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([1,10]))\n",
    "\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "# 二次代价函数\n",
    "loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(prediction,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x:batch_xs, y:batch_ys})\n",
    "            \n",
    "        acc = sess.run(accuracy, feed_dict={x:mnist.test.images, y:mnist.test.labels})\n",
    "        print(\"Iter \" +str(epoch) + \" , testing accuracy \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 , testing accuracy 0.2671\n",
      "Iter 1 , testing accuracy 0.3398\n",
      "Iter 2 , testing accuracy 0.3949\n",
      "Iter 3 , testing accuracy 0.4252\n",
      "Iter 4 , testing accuracy 0.4372\n",
      "Iter 5 , testing accuracy 0.4491\n",
      "Iter 6 , testing accuracy 0.4571\n",
      "Iter 7 , testing accuracy 0.4627\n",
      "Iter 8 , testing accuracy 0.4695\n",
      "Iter 9 , testing accuracy 0.4821\n",
      "Iter 10 , testing accuracy 0.5023\n",
      "Iter 11 , testing accuracy 0.5231\n",
      "Iter 12 , testing accuracy 0.5506\n",
      "Iter 13 , testing accuracy 0.5738\n",
      "Iter 14 , testing accuracy 0.5944\n",
      "Iter 15 , testing accuracy 0.616\n",
      "Iter 16 , testing accuracy 0.6234\n",
      "Iter 17 , testing accuracy 0.6365\n",
      "Iter 18 , testing accuracy 0.6463\n",
      "Iter 19 , testing accuracy 0.6569\n",
      "Iter 20 , testing accuracy 0.6617\n",
      "Iter 21 , testing accuracy 0.671\n",
      "Iter 22 , testing accuracy 0.6787\n",
      "Iter 23 , testing accuracy 0.6851\n",
      "Iter 24 , testing accuracy 0.7148\n",
      "Iter 25 , testing accuracy 0.7332\n",
      "Iter 26 , testing accuracy 0.7405\n",
      "Iter 27 , testing accuracy 0.7526\n",
      "Iter 28 , testing accuracy 0.7577\n",
      "Iter 29 , testing accuracy 0.764\n",
      "Iter 30 , testing accuracy 0.7684\n",
      "Iter 31 , testing accuracy 0.7722\n",
      "Iter 32 , testing accuracy 0.7758\n",
      "Iter 33 , testing accuracy 0.7808\n",
      "Iter 34 , testing accuracy 0.7813\n",
      "Iter 35 , testing accuracy 0.7858\n",
      "Iter 36 , testing accuracy 0.7857\n",
      "Iter 37 , testing accuracy 0.7874\n",
      "Iter 38 , testing accuracy 0.789\n",
      "Iter 39 , testing accuracy 0.7909\n",
      "Iter 40 , testing accuracy 0.7913\n",
      "Iter 41 , testing accuracy 0.7955\n",
      "Iter 42 , testing accuracy 0.7952\n",
      "Iter 43 , testing accuracy 0.7961\n",
      "Iter 44 , testing accuracy 0.7967\n",
      "Iter 45 , testing accuracy 0.7978\n",
      "Iter 46 , testing accuracy 0.7998\n",
      "Iter 47 , testing accuracy 0.7983\n",
      "Iter 48 , testing accuracy 0.8014\n",
      "Iter 49 , testing accuracy 0.8004\n",
      "Iter 50 , testing accuracy 0.8025\n",
      "Iter 51 , testing accuracy 0.8011\n",
      "Iter 52 , testing accuracy 0.8031\n",
      "Iter 53 , testing accuracy 0.8046\n",
      "Iter 54 , testing accuracy 0.8036\n",
      "Iter 55 , testing accuracy 0.8035\n",
      "Iter 56 , testing accuracy 0.8052\n",
      "Iter 57 , testing accuracy 0.807\n",
      "Iter 58 , testing accuracy 0.8061\n",
      "Iter 59 , testing accuracy 0.8073\n",
      "Iter 60 , testing accuracy 0.8072\n",
      "Iter 61 , testing accuracy 0.8088\n",
      "Iter 62 , testing accuracy 0.808\n",
      "Iter 63 , testing accuracy 0.808\n",
      "Iter 64 , testing accuracy 0.8082\n",
      "Iter 65 , testing accuracy 0.8082\n",
      "Iter 66 , testing accuracy 0.8077\n",
      "Iter 67 , testing accuracy 0.8082\n",
      "Iter 68 , testing accuracy 0.8078\n",
      "Iter 69 , testing accuracy 0.809\n",
      "Iter 70 , testing accuracy 0.8095\n",
      "Iter 71 , testing accuracy 0.81\n",
      "Iter 72 , testing accuracy 0.8102\n",
      "Iter 73 , testing accuracy 0.8099\n",
      "Iter 74 , testing accuracy 0.8091\n",
      "Iter 75 , testing accuracy 0.8114\n",
      "Iter 76 , testing accuracy 0.812\n",
      "Iter 77 , testing accuracy 0.8122\n",
      "Iter 78 , testing accuracy 0.8123\n",
      "Iter 79 , testing accuracy 0.8129\n",
      "Iter 80 , testing accuracy 0.8128\n",
      "Iter 81 , testing accuracy 0.8125\n",
      "Iter 82 , testing accuracy 0.813\n",
      "Iter 83 , testing accuracy 0.8132\n",
      "Iter 84 , testing accuracy 0.8128\n",
      "Iter 85 , testing accuracy 0.8152\n",
      "Iter 86 , testing accuracy 0.8152\n",
      "Iter 87 , testing accuracy 0.814\n",
      "Iter 88 , testing accuracy 0.8132\n",
      "Iter 89 , testing accuracy 0.8156\n",
      "Iter 90 , testing accuracy 0.8149\n",
      "Iter 91 , testing accuracy 0.8152\n",
      "Iter 92 , testing accuracy 0.8159\n",
      "Iter 93 , testing accuracy 0.8158\n",
      "Iter 94 , testing accuracy 0.8164\n",
      "Iter 95 , testing accuracy 0.816\n",
      "Iter 96 , testing accuracy 0.8159\n",
      "Iter 97 , testing accuracy 0.8146\n",
      "Iter 98 , testing accuracy 0.8167\n",
      "Iter 99 , testing accuracy 0.8171\n",
      "Iter 100 , testing accuracy 0.8157\n",
      "Iter 101 , testing accuracy 0.816\n",
      "Iter 102 , testing accuracy 0.8149\n",
      "Iter 103 , testing accuracy 0.817\n",
      "Iter 104 , testing accuracy 0.816\n",
      "Iter 105 , testing accuracy 0.8161\n",
      "Iter 106 , testing accuracy 0.8158\n",
      "Iter 107 , testing accuracy 0.8165\n",
      "Iter 108 , testing accuracy 0.8175\n",
      "Iter 109 , testing accuracy 0.8161\n",
      "Iter 110 , testing accuracy 0.8187\n",
      "Iter 111 , testing accuracy 0.818\n",
      "Iter 112 , testing accuracy 0.8184\n",
      "Iter 113 , testing accuracy 0.8183\n",
      "Iter 114 , testing accuracy 0.8174\n",
      "Iter 115 , testing accuracy 0.8163\n",
      "Iter 116 , testing accuracy 0.8162\n",
      "Iter 117 , testing accuracy 0.819\n",
      "Iter 118 , testing accuracy 0.8188\n",
      "Iter 119 , testing accuracy 0.8184\n",
      "Iter 120 , testing accuracy 0.8184\n",
      "Iter 121 , testing accuracy 0.8169\n",
      "Iter 122 , testing accuracy 0.8182\n",
      "Iter 123 , testing accuracy 0.8165\n",
      "Iter 124 , testing accuracy 0.8174\n",
      "Iter 125 , testing accuracy 0.8183\n",
      "Iter 126 , testing accuracy 0.8189\n",
      "Iter 127 , testing accuracy 0.8191\n",
      "Iter 128 , testing accuracy 0.8193\n",
      "Iter 129 , testing accuracy 0.8203\n",
      "Iter 130 , testing accuracy 0.8196\n",
      "Iter 131 , testing accuracy 0.8196\n",
      "Iter 132 , testing accuracy 0.8192\n",
      "Iter 133 , testing accuracy 0.8185\n",
      "Iter 134 , testing accuracy 0.8191\n",
      "Iter 135 , testing accuracy 0.8199\n",
      "Iter 136 , testing accuracy 0.8193\n",
      "Iter 137 , testing accuracy 0.8187\n",
      "Iter 138 , testing accuracy 0.8203\n",
      "Iter 139 , testing accuracy 0.8191\n",
      "Iter 140 , testing accuracy 0.8202\n",
      "Iter 141 , testing accuracy 0.8206\n",
      "Iter 142 , testing accuracy 0.8194\n",
      "Iter 143 , testing accuracy 0.8211\n",
      "Iter 144 , testing accuracy 0.8193\n",
      "Iter 145 , testing accuracy 0.82\n",
      "Iter 146 , testing accuracy 0.82\n",
      "Iter 147 , testing accuracy 0.8204\n",
      "Iter 148 , testing accuracy 0.8214\n",
      "Iter 149 , testing accuracy 0.8215\n",
      "Iter 150 , testing accuracy 0.8219\n",
      "Iter 151 , testing accuracy 0.8203\n",
      "Iter 152 , testing accuracy 0.8208\n",
      "Iter 153 , testing accuracy 0.8217\n",
      "Iter 154 , testing accuracy 0.8209\n",
      "Iter 155 , testing accuracy 0.8211\n",
      "Iter 156 , testing accuracy 0.8213\n",
      "Iter 157 , testing accuracy 0.8219\n",
      "Iter 158 , testing accuracy 0.8213\n",
      "Iter 159 , testing accuracy 0.8209\n",
      "Iter 160 , testing accuracy 0.8212\n",
      "Iter 161 , testing accuracy 0.8232\n",
      "Iter 162 , testing accuracy 0.8217\n",
      "Iter 163 , testing accuracy 0.8226\n",
      "Iter 164 , testing accuracy 0.8213\n",
      "Iter 165 , testing accuracy 0.8226\n",
      "Iter 166 , testing accuracy 0.8211\n",
      "Iter 167 , testing accuracy 0.8235\n",
      "Iter 168 , testing accuracy 0.8226\n",
      "Iter 169 , testing accuracy 0.8227\n",
      "Iter 170 , testing accuracy 0.8228\n",
      "Iter 171 , testing accuracy 0.823\n",
      "Iter 172 , testing accuracy 0.8228\n",
      "Iter 173 , testing accuracy 0.8235\n",
      "Iter 174 , testing accuracy 0.8233\n",
      "Iter 175 , testing accuracy 0.8241\n",
      "Iter 176 , testing accuracy 0.8235\n",
      "Iter 177 , testing accuracy 0.8229\n",
      "Iter 178 , testing accuracy 0.8225\n",
      "Iter 179 , testing accuracy 0.8241\n",
      "Iter 180 , testing accuracy 0.8229\n",
      "Iter 181 , testing accuracy 0.8226\n",
      "Iter 182 , testing accuracy 0.8227\n",
      "Iter 183 , testing accuracy 0.8234\n",
      "Iter 184 , testing accuracy 0.823\n",
      "Iter 185 , testing accuracy 0.8241\n",
      "Iter 186 , testing accuracy 0.8228\n",
      "Iter 187 , testing accuracy 0.8247\n",
      "Iter 188 , testing accuracy 0.8245\n",
      "Iter 189 , testing accuracy 0.8245\n",
      "Iter 190 , testing accuracy 0.8239\n",
      "Iter 191 , testing accuracy 0.8244\n",
      "Iter 192 , testing accuracy 0.8241\n",
      "Iter 193 , testing accuracy 0.8249\n",
      "Iter 194 , testing accuracy 0.8238\n",
      "Iter 195 , testing accuracy 0.8219\n",
      "Iter 196 , testing accuracy 0.8242\n",
      "Iter 197 , testing accuracy 0.8244\n",
      "Iter 198 , testing accuracy 0.8244\n",
      "Iter 199 , testing accuracy 0.8246\n",
      "Iter 200 , testing accuracy 0.8241\n",
      "Iter 201 , testing accuracy 0.8249\n",
      "Iter 202 , testing accuracy 0.8261\n",
      "Iter 203 , testing accuracy 0.8249\n",
      "Iter 204 , testing accuracy 0.8247\n",
      "Iter 205 , testing accuracy 0.8249\n",
      "Iter 206 , testing accuracy 0.8251\n",
      "Iter 207 , testing accuracy 0.824\n",
      "Iter 208 , testing accuracy 0.8238\n",
      "Iter 209 , testing accuracy 0.8243\n",
      "Iter 210 , testing accuracy 0.8245\n",
      "Iter 211 , testing accuracy 0.8239\n",
      "Iter 212 , testing accuracy 0.8238\n",
      "Iter 213 , testing accuracy 0.8239\n",
      "Iter 214 , testing accuracy 0.8244\n",
      "Iter 215 , testing accuracy 0.8246\n",
      "Iter 216 , testing accuracy 0.8246\n",
      "Iter 217 , testing accuracy 0.8238\n",
      "Iter 218 , testing accuracy 0.8244\n",
      "Iter 219 , testing accuracy 0.8243\n",
      "Iter 220 , testing accuracy 0.8251\n",
      "Iter 221 , testing accuracy 0.8252\n",
      "Iter 222 , testing accuracy 0.8234\n",
      "Iter 223 , testing accuracy 0.8245\n",
      "Iter 224 , testing accuracy 0.8229\n",
      "Iter 225 , testing accuracy 0.8253\n",
      "Iter 226 , testing accuracy 0.8243\n",
      "Iter 227 , testing accuracy 0.8247\n",
      "Iter 228 , testing accuracy 0.8257\n",
      "Iter 229 , testing accuracy 0.8245\n",
      "Iter 230 , testing accuracy 0.8248\n",
      "Iter 231 , testing accuracy 0.8249\n",
      "Iter 232 , testing accuracy 0.8254\n",
      "Iter 233 , testing accuracy 0.8245\n",
      "Iter 234 , testing accuracy 0.8245\n",
      "Iter 235 , testing accuracy 0.8246\n",
      "Iter 236 , testing accuracy 0.8245\n",
      "Iter 237 , testing accuracy 0.8256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 238 , testing accuracy 0.823\n",
      "Iter 239 , testing accuracy 0.8252\n",
      "Iter 240 , testing accuracy 0.8262\n",
      "Iter 241 , testing accuracy 0.8238\n",
      "Iter 242 , testing accuracy 0.8245\n",
      "Iter 243 , testing accuracy 0.8249\n",
      "Iter 244 , testing accuracy 0.8259\n",
      "Iter 245 , testing accuracy 0.8253\n",
      "Iter 246 , testing accuracy 0.8255\n",
      "Iter 247 , testing accuracy 0.8259\n",
      "Iter 248 , testing accuracy 0.8258\n",
      "Iter 249 , testing accuracy 0.8251\n",
      "Iter 250 , testing accuracy 0.8254\n",
      "Iter 251 , testing accuracy 0.8252\n",
      "Iter 252 , testing accuracy 0.8243\n",
      "Iter 253 , testing accuracy 0.8259\n",
      "Iter 254 , testing accuracy 0.8245\n",
      "Iter 255 , testing accuracy 0.8246\n",
      "Iter 256 , testing accuracy 0.8249\n",
      "Iter 257 , testing accuracy 0.8267\n",
      "Iter 258 , testing accuracy 0.8265\n",
      "Iter 259 , testing accuracy 0.8258\n",
      "Iter 260 , testing accuracy 0.8253\n",
      "Iter 261 , testing accuracy 0.8258\n",
      "Iter 262 , testing accuracy 0.826\n",
      "Iter 263 , testing accuracy 0.8258\n",
      "Iter 264 , testing accuracy 0.8248\n",
      "Iter 265 , testing accuracy 0.8261\n",
      "Iter 266 , testing accuracy 0.8246\n",
      "Iter 267 , testing accuracy 0.8247\n",
      "Iter 268 , testing accuracy 0.8263\n",
      "Iter 269 , testing accuracy 0.8256\n",
      "Iter 270 , testing accuracy 0.825\n",
      "Iter 271 , testing accuracy 0.8255\n",
      "Iter 272 , testing accuracy 0.825\n",
      "Iter 273 , testing accuracy 0.8253\n",
      "Iter 274 , testing accuracy 0.8251\n",
      "Iter 275 , testing accuracy 0.8261\n",
      "Iter 276 , testing accuracy 0.8257\n",
      "Iter 277 , testing accuracy 0.8248\n",
      "Iter 278 , testing accuracy 0.8247\n",
      "Iter 279 , testing accuracy 0.8247\n",
      "Iter 280 , testing accuracy 0.8256\n",
      "Iter 281 , testing accuracy 0.8254\n",
      "Iter 282 , testing accuracy 0.8252\n",
      "Iter 283 , testing accuracy 0.8247\n",
      "Iter 284 , testing accuracy 0.825\n",
      "Iter 285 , testing accuracy 0.8269\n",
      "Iter 286 , testing accuracy 0.8249\n",
      "Iter 287 , testing accuracy 0.8246\n",
      "Iter 288 , testing accuracy 0.8261\n",
      "Iter 289 , testing accuracy 0.8256\n",
      "Iter 290 , testing accuracy 0.8243\n",
      "Iter 291 , testing accuracy 0.8251\n",
      "Iter 292 , testing accuracy 0.8251\n",
      "Iter 293 , testing accuracy 0.823\n",
      "Iter 294 , testing accuracy 0.8249\n",
      "Iter 295 , testing accuracy 0.8252\n",
      "Iter 296 , testing accuracy 0.8255\n",
      "Iter 297 , testing accuracy 0.8257\n",
      "Iter 298 , testing accuracy 0.8255\n",
      "Iter 299 , testing accuracy 0.8253\n"
     ]
    }
   ],
   "source": [
    "# 每个批次的大小 每次放入100张图片\n",
    "batch_size = 40\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size  # 整除\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#创建神经网路\n",
    "\n",
    "Weight_L1 = tf.Variable(tf.random_normal([784,200]))\n",
    "biases_L1 = tf.Variable(tf.random_normal([1,200]))\n",
    "Wx_plus_b_L1 = tf.matmul(x, Weight_L1) + biases_L1\n",
    "#L1 = tf.nn.tanh(Wx_plus_b_L1)\n",
    "#L1 = tf.nn.softmax(Wx_plus_b_L1)\n",
    "L1 = Wx_plus_b_L1\n",
    "\n",
    "#Weight_L2 = tf.Variable(tf.random_normal([200,10]))\n",
    "Weight_L2 = tf.Variable(tf.random_normal([200,10]))\n",
    "biases_L2 = tf.Variable(tf.random_normal([1,10]))\n",
    "Wx_plus_b_L2 = tf.matmul(L1, Weight_L2) + biases_L2\n",
    "\n",
    "#b = tf.Variable(tf.zeros([1,10]))\n",
    "#L2 = tf.nn.tanh(Wx_plus_b_L2)\n",
    "L2 = Wx_plus_b_L2\n",
    "\n",
    "prediction = tf.nn.softmax(L2)\n",
    "\n",
    "\n",
    "# 二次代价函数\n",
    "loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(prediction,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(300):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x:batch_xs, y:batch_ys})\n",
    "            \n",
    "        acc = sess.run(accuracy, feed_dict={x:mnist.test.images, y:mnist.test.labels})\n",
    "        print(\"Iter \" +str(epoch) + \" , testing accuracy \" + str(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 , testing accuracy 0.881\n",
      "Iter 1 , testing accuracy 0.9044\n",
      "Iter 2 , testing accuracy 0.9128\n",
      "Iter 3 , testing accuracy 0.9161\n",
      "Iter 4 , testing accuracy 0.9223\n",
      "Iter 5 , testing accuracy 0.9229\n",
      "Iter 6 , testing accuracy 0.9248\n",
      "Iter 7 , testing accuracy 0.9275\n",
      "Iter 8 , testing accuracy 0.928\n",
      "Iter 9 , testing accuracy 0.9283\n",
      "Iter 10 , testing accuracy 0.9322\n",
      "Iter 11 , testing accuracy 0.9308\n",
      "Iter 12 , testing accuracy 0.9327\n",
      "Iter 13 , testing accuracy 0.9339\n",
      "Iter 14 , testing accuracy 0.9362\n",
      "Iter 15 , testing accuracy 0.9361\n",
      "Iter 16 , testing accuracy 0.9366\n",
      "Iter 17 , testing accuracy 0.9346\n",
      "Iter 18 , testing accuracy 0.9371\n",
      "Iter 19 , testing accuracy 0.9372\n",
      "Iter 20 , testing accuracy 0.9375\n",
      "Iter 21 , testing accuracy 0.9384\n",
      "Iter 22 , testing accuracy 0.9395\n",
      "Iter 23 , testing accuracy 0.9384\n",
      "Iter 24 , testing accuracy 0.9386\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-07795bbbb190>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 成功代码 \n",
    "#每个批次的大小 每次放入100张图片 这一段比较成功，因为初始化使用了truncated\n",
    "batch_size = 40\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size  # 整除\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#创建神经网路\n",
    "\n",
    "Weight_L1 = tf.Variable(tf.truncated_normal([784,20], stddev=0.1))\n",
    "biases_L1 = tf.Variable(tf.random_normal([1,20])+0.1)\n",
    "Wx_plus_b_L1 = tf.matmul(x, Weight_L1) + biases_L1\n",
    "L1 = tf.nn.tanh(Wx_plus_b_L1)\n",
    "#L1 = tf.nn.softmax(Wx_plus_b_L1)\n",
    "#L1 = Wx_plus_b_L1\n",
    "\n",
    "#Weight_L2 = tf.Variable(tf.random_normal([20,10]))\n",
    "Weight_L2 = tf.Variable(tf.truncated_normal([20,10], stddev=0.1))\n",
    "biases_L2 = tf.Variable(tf.zeros([1,10]) + 0.1)\n",
    "Wx_plus_b_L2 = tf.matmul(L1, Weight_L2) + biases_L2\n",
    "#L2 = Wx_plus_b_L2\n",
    "#b = tf.Variable(tf.zeros([1,10]))\n",
    "L2 = tf.nn.tanh(Wx_plus_b_L2)\n",
    "\n",
    "\n",
    "prediction = tf.nn.softmax(L2)\n",
    "\n",
    "\n",
    "# 二次代价函数\n",
    "#loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(prediction,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(200):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x:batch_xs, y:batch_ys})\n",
    "            \n",
    "        acc = sess.run(accuracy, feed_dict={x:mnist.test.images, y:mnist.test.labels})\n",
    "        print(\"Iter \" +str(epoch) + \" , testing accuracy \" + str(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每个批次的大小 每次放入100张图片\n",
    "batch_size = 40\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size  # 整除\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "#创建神经网路\n",
    "\n",
    "Weight_L1 = tf.Variable(tf.truncated_normal([784,2000], stddev=0.1))\n",
    "biases_L1 = tf.Variable(tf.zeros([1,2000]) + 0.1)\n",
    "Wx_plus_b_L1 = tf.matmul(x, Weight_L1) + biases_L1\n",
    "L1 = tf.nn.tanh(Wx_plus_b_L1)\n",
    "L1_drop = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "Weight_L2 = tf.Variable(tf.truncated_normal([2000,2000], stddev=0.1))\n",
    "biases_L2 = tf.Variable(tf.zeros([1,2000]) + 0.1)\n",
    "Wx_plus_b_L2 = tf.matmul(L1_drop, Weight_L2) + biases_L2\n",
    "L2 = tf.nn.tanh(Wx_plus_b_L2)\n",
    "L2_drop = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "Weight_L3 = tf.Variable(tf.truncated_normal([2000,1000], stddev=0.1))\n",
    "biases_L3 = tf.Variable(tf.zeros([1,1000]) + 0.1)\n",
    "Wx_plus_b_L3 = tf.matmul(L2_drop, Weight_L3) + biases_L3\n",
    "L3 = tf.nn.tanh(Wx_plus_b_L3)\n",
    "L3_drop = tf.nn.dropout(L3, keep_prob)\n",
    "\n",
    "Weight_L4 = tf.Variable(tf.truncated_normal([1000,10], stddev=0.1))\n",
    "biases_L4 = tf.Variable(tf.zeros([1,10]) + 0.1)\n",
    "Wx_plus_b_L4 = tf.matmul(L3_drop, Weight_L4) + biases_L4\n",
    "\n",
    "\n",
    "prediction = tf.nn.softmax(Wx_plus_b_L4)\n",
    "\n",
    "\n",
    "# 二次代价函数\n",
    "#loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(prediction,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(31):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x:batch_xs, y:batch_ys, keep_prob:0.7})\n",
    "            \n",
    "        test_acc = sess.run(accuracy, feed_dict={x:mnist.test.images, y:mnist.test.labels, keep_prob:1.0})\n",
    "        train_acc = sess.run(accuracy, feed_dict={x:mnist.train.images, y:mnist.train.labels, keep_prob:1.0})\n",
    "        print(\"Iter \" +str(epoch) + \" , testing accuracy \" + str(test_acc) + \"training accuracy\" + str(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.4934659  -1.6814771  -1.0092992   0.24638882  0.04726779]]\n"
     ]
    }
   ],
   "source": [
    "# 成功输出变量的片段\n",
    "import tensorflow as tf;\n",
    "A = tf.Variable(tf.random_normal([1,5]) + 0.1, dtype=tf.float32)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "[-0.821463  -2.1496346]\n",
      "[[-0.821463  -2.1496346]\n",
      " [-0.821463  -2.1496346]\n",
      " [-0.821463  -2.1496346]]\n"
     ]
    }
   ],
   "source": [
    "# 这一段解释了程序里的疑惑。 这里直接矩阵相加，只会是横着拍上去！！竖着的，不知道怎么搞\n",
    "mx = tf.Variable(tf.zeros([3, 2]), dtype=tf.float32)\n",
    "b = tf.Variable(tf.random_normal([2]) , dtype=tf.float32)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(mx))\n",
    "    print(sess.run(b))\n",
    "    result = mx + b\n",
    "    print(sess.run(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta = ta + 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1, 2.1, 3.1, 4.1])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = tf.nn.softmax(ta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_4:0' shape=(4,) dtype=float64>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0320586  0.08714432 0.23688282 0.64391426]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(tb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
